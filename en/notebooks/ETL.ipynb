{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EEJO_jG6MIT",
        "colab_type": "text"
      },
      "source": [
        "# Extract, transform and load data (ETL) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk3uuY8rA_uT",
        "colab_type": "text"
      },
      "source": [
        "The ETL process is a fundamental part of working with data and is based on three steps:\n",
        "\n",
        "*   **Extraction**: collecting data, potentially from multiple heterogeneous sources. It can involve scraping web pages, access to programming interfaces (APIs), or consulting databases.\n",
        "*   **Transformation**: reorganizing data, involving operations such as merging and aggregation.\n",
        "*   **Load**: persistence of the new dataset where one wants to store it.\n",
        "\n",
        "This notebook focuses on examples of transformation with Pandas. For this, we will use three dataframes in our examples: `df_a`, `df_b` and `df_c`.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w0Ufe3d64DG",
        "colab_type": "text"
      },
      "source": [
        "## Creating dataframes from dictionaries\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsgGHYp5BED3",
        "colab_type": "text"
      },
      "source": [
        "Since we'll create customized dataframes, we'll need the help of **dictionaries**. A dictionary is an object type in Python which stores values indexed by keys, similar to what `DataFrame` does. We use the following notation for creating a dictionary:\n",
        "\n",
        "```\n",
        "name = {\n",
        "        key1: value1,\n",
        "        key2: value2,\n",
        "        ...\n",
        "        keyN: valueN\n",
        "        }\n",
        "```\n",
        "We access a value in a dictionary through its key, with the `dictionary[key]` notation. In the following example, the dictionary `data_df_a` has feature names as keys, and the associated data series as values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xA7utuCBEX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_e6KIctBElU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df_a = {\n",
        "            'id_individual': ['1', '2', '3', '4', '5'],\n",
        "            'name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
        "            'surname': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec4b76d9BE03",
        "colab_type": "text"
      },
      "source": [
        "Note that each series is represented as a list.  Creating a `DataFrame` from a list is really simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRF20ifhBGNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_a = pd.DataFrame(data_df_a)\n",
        "df_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwQ-nmgcBGUv",
        "colab_type": "text"
      },
      "source": [
        "Following the same approach, let's create dataframe `df_b`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdqaySrLBMlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df_b = {\n",
        "            'id_individual': ['4', '5', '6', '7', '8'],\n",
        "            'name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
        "            'surname': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AgCCpraBMtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_b = pd.DataFrame(data_df_b)\n",
        "df_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NmYyDk_BM2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df_c = {\n",
        "            'id_individual': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
        "            'id_exam': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2C4H5RkBM9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_c = pd.DataFrame(data_df_c)\n",
        "df_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d--hw56V7DEv"
      },
      "source": [
        "## Appending data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzTz4xs3BT8_",
        "colab_type": "text"
      },
      "source": [
        "One of the common operations is to concatenate samples that have the same features, but that are in different dataframes.  For this we will use the `concat` command, which receives a list with ***n*** `DataFrame` objects as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfbKS_PJBUNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_new = pd.concat([df_a, df_b])\n",
        "df_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ8xFZ-NBUTn",
        "colab_type": "text"
      },
      "source": [
        "It's also possible to concatenate `DataFrame` objects with distinct features. However, this operation would produce a `DataFrame` with many missing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMhDTAHY8zUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([df_a, df_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NHdshguT9kpz"
      },
      "source": [
        "## Merging data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsd3TBFT9tns",
        "colab_type": "text"
      },
      "source": [
        "In the previous example, we saw the result of the concatenating data between different `DataFrames` whose features are not identical. However, when there is at least one feature in common between two `DataFrames`, we can use the technique called **data merging**, using the pandas **merge** method, which returns a new `DataFrame` containing the combined data from the two base `DataFrames`.\n",
        "\n",
        "In the example below, the samples of the `DataFrame` on the left (```df_a```) and the `DataFrame` on the right (```df_c```) are merged, taking ```id_individual``` as a common feature. As you can see, the new `DataFrame` gathers information from both `DataFrames` used to merge data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7yS9sej9rfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df_a, df_c, on='id_individual')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG8yh9HL9uV8",
        "colab_type": "text"
      },
      "source": [
        "In summary, the **merging** operation combines the data from two `DataFrames` with at least one common **feature**. In the previous example, the common feature was the **id_individual** field. In other situations, the same feature may be represented by different names in the `DataFrames` one wants to merge. In this case, we use arguments `left_on` and `right_on` to respectively specify the names of the features in the `DataFrame` on the left and in the `DataFrame` on the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ICEg3nBN7RyB"
      },
      "source": [
        "### Merge types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu-UT39LBYTz",
        "colab_type": "text"
      },
      "source": [
        "Note that the samples present in the `df_c` dataframe whose values ​​for `id_individual` are not present in the `df_a` dataframe were not shown. If we want these samples to be preserved, we can use a **right join**. We specify that we want a right join using the argument `how`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ85UpYSBYhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df_a, df_c, on='id_individual', how='right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wiklj-3BYrn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The result above shows both the samples with `id_individual` present in the two `DataFrames` and the rest of the samples on the right `DataFrame`. Note that the samples added by the intersection on the right have missing data. The **left join** also has the same behavior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCyrZfVLBYy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df_b, df_c, on='id_individual', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCwBR2A1BY49",
        "colab_type": "text"
      },
      "source": [
        "In this case, the sample of the `df_b` dataframe whose `id_individual` was not present in the `df_c` dataframe was maintained. In a more extreme case, we can use an **external merging**, which holds all samples from both dataframes. Instead of **right** or **left**, we set `how` to **outer**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlt5taboBZAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df_b, df_c, on='id_individual', how='outer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rAphyQC_7gco"
      },
      "source": [
        "## Aggregating data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5SCH_VbBav_",
        "colab_type": "text"
      },
      "source": [
        "Merging operations aim to gather information spread across multiple bases on a single `DataFrame`. A complementary type of operation is **aggregation**, which aims to summarize blocks of information using **descriptive statistics**. The main forms of aggregation are obtained through **pivoting**, be it one-dimensional (**groups**)\n",
        " or two-dimensional (**pivot** **tables**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cYyGcdd07qL4"
      },
      "source": [
        "### Groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Xa3PyhBgTb",
        "colab_type": "text"
      },
      "source": [
        "Organizing data into groups can be useful to analyse each group or to calculate per-group statistics. The first step for aggregation is to define one or more features to be used as grouping factors.   In the example below, we group the data from the `iris` dataset.  This dataset is the most downloaded of the machine learning repository [UCI](https://archive.ics.uci.edu/ml/). It lists petal and sepal measurements of three species of iris flowers. For convenience, we are going to download it from the `seaborn` library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boHi_1XlBgbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "iris_dataset = sns.load_dataset('iris')\n",
        "iris_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfwGEx03Bgib",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the dataset contains sepal and petal widths and heights of 150 iris flowers samples. Let's see how many samples we have per species: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69nD8aSLBgoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_dataset['species'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8hsNEtGBgv9",
        "colab_type": "text"
      },
      "source": [
        "To group this dataset by species, we can use the `groupby()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYnHlDFhBg4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_groups = iris_dataset.groupby(['species'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPM8p6jABg_i",
        "colab_type": "text"
      },
      "source": [
        "We can then treat each group as a `DataFrame` using the `get_group()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ-uEOc-BhHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_groups.get_group('versicolor').head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvgYikt6BhvZ",
        "colab_type": "text"
      },
      "source": [
        "Grouping allow us to compute statistics about the all groups at the same time or individually:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iaT9Dy0370K7"
      },
      "source": [
        "#### At the same time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsEy_9hEBkIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_groups.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLau61OzBkP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_groups.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sguL5gCABkVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_groups.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sIDkzSYN7p1I"
      },
      "source": [
        "#### Individually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sgw7MgDBl5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_groups.get_group(\"versicolor\").describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYrl3PM8Bl_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "versicolor_group = iris_groups.get_group(\"versicolor\")\n",
        "versicolor_group.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2Zaf_ic7rd_"
      },
      "source": [
        "#### Aggregating multiple features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03yN1hQhBqAR",
        "colab_type": "text"
      },
      "source": [
        "A powerful resource of Pandas is to allow aggregations of multiple features. In general, we use this resource when we have a set of data that has categorical and numerical features. In the `iris` dataset, however, we only have one categorical feature available. Let's take advantage of this situation and take a look at a really cool feature of Pandas, called discretization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZjICJrbBqFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.cut(iris_dataset[\"petal_width\"], bins=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZePc6iAwBqRO",
        "colab_type": "text"
      },
      "source": [
        "Did you understand what happened? The `cut()` method calculated the maximum and minimum values for the `petal_width` feature and split this interval into three subintervals. Thus, each of the original values was replaced by the sub-interval to which it belongs and, now, we have a categorical feature 😄\n",
        "\n",
        "Let's replace the original data with categorized data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQCXpPHRBqWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_dataset[\"petal_width\"] = pd.cut(iris_dataset[\"petal_width\"], bins=3)\n",
        "iris_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgjEwrZZBqcs",
        "colab_type": "text"
      },
      "source": [
        "For readability, let's rename the categories created. Note that this time we are changing the original data directly using the option `inplace=True` (almost all Pandas methods accept this option)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc6chAGEBqi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_dataset[\"petal_width\"].cat.rename_categories([\"low\", \"medium\", \"high\"], inplace=True)\n",
        "iris_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68IiapMKBqpn",
        "colab_type": "text"
      },
      "source": [
        "Now that our dataset has two categorical features, we can aggregate by multiple features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOZutKVrBqvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group2_iris = iris_dataset.groupby([\"species\",\"petal_width\"]).size()\n",
        "group2_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV6jBWKKBq17",
        "colab_type": "text"
      },
      "source": [
        "In this case, instead of producing the groups, we directly produce the aggregation using the `size()` method, which computes the size of each group. From the data above, we can see that all iris flowers of the `setosa` species present in the dataset have a small petal width. It is also possible to make an excellent separation between the `versicolor` and `virginica` species.\n",
        "\n",
        "Note that the data above is a series that has a multi-level index (known in Pandas as `MultiIndex`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPfr2JlbBq6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group2_iris.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la70vEZuBwzB",
        "colab_type": "text"
      },
      "source": [
        "Amid the verbose messages of Pandas, we see that there are two levels in this index (`levels`), whose names (`names`) are `species` and `petal_width`. We can index this series in several different ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5EKD6NVBxAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group2_iris[\"virginica\",\"high\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWIWzSjGBxHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group2_iris[\"virginica\",]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F926Z9a8BxOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group2_iris[:,\"high\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUxqIUBMBxa-",
        "colab_type": "text"
      },
      "source": [
        "We can also convert this series into a `DataFrame`. For this, we use the `reset_index()` method and inform the name we want to give to the series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB6nEcIuBxiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_iris = group2_iris.reset_index(name=\"count\")\n",
        "df_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ylty4CtM7rln"
      },
      "source": [
        "### Pivot tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am3cMEp9B0VE",
        "colab_type": "text"
      },
      "source": [
        "Another form of aggregation available in Pandas is through pivot tables. In this case, we use the `pivot_table()` method. We must inform the features for the grouping at the level of rows (`index`) and columns (` columns`). We also can inform the aggregation method using the `aggfunc` option, which by default calculates the mean:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju-3vBWzB0cT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_iris = iris_dataset.pivot_table(index=\"species\", columns=\"petal_width\", aggfunc=\"size\")\n",
        "pt_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chniLZo3B0hd",
        "colab_type": "text"
      },
      "source": [
        "Note that the pivot table tries to generate all possible combinations between row and column features. Since our dataset does not have samples of the `setosa` species with petal width `medium` or `high`, these values are marked as missing/invalid. The `pivot_table()` method provides the `fill_value` option, which allow us to choose how to fill these cases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPe3eskZB0oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_iris = iris_dataset.pivot_table(index=\"species\", columns=\"petal_width\", aggfunc=\"size\", fill_value=0)\n",
        "pt_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uDi3sk_B0v6",
        "colab_type": "text"
      },
      "source": [
        "The `pivot_table()` produces an object of type `DataFrame`, so the indexing works the way we already know:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slUmJBSpB03i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_iris.loc[\"versicolor\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x0WZR8jB0-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_iris.loc[\"versicolor\",\"low\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S35SVpRvB1F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_iris.loc[:,\"low\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeCe4S97NrCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}